"""
Local testing script - simulates Lambda workflow without AWS
Tests: data fetching ‚Üí feature preparation ‚Üí model prediction
"""

import sys
import os
from datetime import datetime, timedelta
import pandas as pd
import numpy as np

# Add paths
sys.path.insert(0, 'utils')

print("="*80)
print("LOCAL PREDICTION TEST")
print("="*80)

# Test 1: Import your modules
print("\n1Ô∏è‚É£  Testing imports...")
try:
    from integrated_pipeline import (
        fetch_stock_data,
        calculate_technical_indicators,
        generate_simple_alphas,
        prepare_dataframe_for_alpha
    )
    from lstm_predictor import (
        ImprovedDualStreamLSTM,
        ModelEnsemble,
        prepare_data_with_fixes,
        load_ensemble
    )
    import torch
    print("   ‚úì All imports successful")
except ImportError as e:
    print(f"   ‚úó Import failed: {e}")
    sys.exit(1)

# Test 2: Fetch real stock data
print("\n2Ô∏è‚É£  Fetching stock data...")
ticker = "AAPL"
end_date = datetime.now()
start_date = end_date - timedelta(days=90)

try:
    stock_df = fetch_stock_data(
        ticker,
        start_date.isoformat() + 'Z',
        end_date.isoformat() + 'Z'
    )
    print(f"   ‚úì Fetched {len(stock_df)} days of data")
    print(f"   Latest close: ${stock_df.iloc[-1]['close']:.2f}")
except Exception as e:
    print(f"   ‚úó Failed: {e}")
    sys.exit(1)

# Test 3: Calculate technical indicators
print("\n3Ô∏è‚É£  Calculating technical indicators...")
try:
    stock_df = calculate_technical_indicators(stock_df)
    print(f"   ‚úì Added technical indicators")
    print(f"   Total columns: {len(stock_df.columns)}")

    # Show some indicators
    indicators = ['RSI', 'MACD', 'SMA_20', 'BB_Upper']
    available = [ind for ind in indicators if ind in stock_df.columns]
    print(f"   Available: {', '.join(available)}")
except Exception as e:
    print(f"   ‚úó Failed: {e}")
    sys.exit(1)

# Test 4: Generate alphas
print("\n4Ô∏è‚É£  Generating alpha formulas...")
try:
    alpha_text = generate_simple_alphas(ticker)
    print(f"   ‚úì Generated alphas")
    print(f"   Preview: {alpha_text[:100]}...")
except Exception as e:
    print(f"   ‚úó Failed: {e}")
    alpha_text = f"Œ±1 = Return_5D\nŒ±2 = RSI / 100"

# Test 5: Prepare comprehensive dataframe
print("\n5Ô∏è‚É£  Preparing features for model...")
try:
    comprehensive_df = prepare_dataframe_for_alpha(
        ticker,
        stock_df,
        {},  # No sentiments
        [],  # No related companies
        None,  # No alternative data
        None   # No economic data
    )
    print(f"   ‚úì Prepared dataframe")
    print(f"   Shape: {comprehensive_df.shape}")
except Exception as e:
    print(f"   ‚úó Failed: {e}")
    sys.exit(1)

# Test 6: Check for trained model
print("\n6Ô∏è‚É£  Checking for trained model...")
model_path = f"../{ticker}_ensemble.pth"

if not os.path.exists(model_path):
    # Try current directory
    model_path = f"{ticker}_ensemble.pth"

if not os.path.exists(model_path):
    # Try looking for individual models
    model_path = f"{ticker}_model_0.pth"

if os.path.exists(model_path):
    print(f"   ‚úì Found model: {model_path}")
    model_size_mb = os.path.getsize(model_path) / (1024*1024)
    print(f"   Model size: {model_size_mb:.1f} MB")

    # Test 7: Load model
    print("\n7Ô∏è‚É£  Loading model...")
    try:
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"   Using device: {device}")

        # Prepare data
        train_loader, val_loader, test_loader, scalers, num_alphas, test_dates, train_df = \
            prepare_data_with_fixes(
                comprehensive_df,
                ticker,
                alpha_text,
                window_size=30,
                use_feature_selection=True,
                top_k=30
            )

        if test_loader is None or len(test_loader.dataset) == 0:
            print("   ‚ö†Ô∏è  Not enough data for prediction window")
            print("   Need at least 60 days of data")
        else:
            # Create dummy model with correct architecture
            dummy_model = ImprovedDualStreamLSTM(
                num_alphas=num_alphas,
                hidden_size=128,
                num_layers=3,
                dropout=0.3,
                num_heads=4
            )

            ensemble = ModelEnsemble([dummy_model])
            ensemble.load_state_dict(torch.load(model_path, map_location=device))
            ensemble.eval()

            print(f"   ‚úì Model loaded successfully")
            print(f"   Num alphas: {num_alphas}")

            # Test 8: Make prediction
            print("\n8Ô∏è‚É£  Making prediction...")

            with torch.no_grad():
                for batch in test_loader:
                    alphas, prices_temporal, targets = batch
                    break

                predictions, uncertainties = ensemble(
                    alphas,
                    prices_temporal,
                    n_samples=10,
                    training=False
                )

                predicted_change = float(predictions[-1][0])
                uncertainty = float(uncertainties[-1][0])

            # Inverse scale
            if 'target' in scalers:
                predicted_change = scalers['target'].inverse_transform([[predicted_change]])[0][0]

            current_price = float(stock_df.iloc[-1]['close'])
            target_price = current_price * (1 + predicted_change)
            direction = 'UP ‚¨ÜÔ∏è' if predicted_change > 0 else 'DOWN ‚¨áÔ∏è'
            confidence = (1 - min(uncertainty, 1.0)) * 100

            print(f"\n{'='*80}")
            print(f"üéØ PREDICTION RESULTS FOR {ticker}")
            print(f"{'='*80}")
            print(f"  Current Price:    ${current_price:.2f}")
            print(f"  Predicted Change: {predicted_change:+.2%}")
            print(f"  Target Price:     ${target_price:.2f}")
            print(f"  Direction:        {direction}")
            print(f"  Confidence:       {confidence:.1f}%")
            print(f"  Uncertainty:      ¬±{uncertainty:.4f}")
            print(f"{'='*80}")

            print("\n‚úÖ LOCAL TEST SUCCESSFUL!")
            print("   Your pipeline is working correctly.")
            print("   Ready to deploy to AWS when you want.")

    except Exception as e:
        print(f"   ‚úó Prediction failed: {e}")
        import traceback
        traceback.print_exc()
else:
    print(f"   ‚ö†Ô∏è  No trained model found for {ticker}")
    print(f"   Expected location: {model_path}")
    print(f"\n   To train a model locally, run:")
    print(f"   cd ~/Trading && python integrated_pipeline.py")
    print(f"\n   Or continue with deployment and train on AWS.")

print("\n" + "="*80)
print("TEST COMPLETE")
print("="*80)